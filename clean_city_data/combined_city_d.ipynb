{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv's , dropping columns, setting index, parsing NA values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'new_york_edited copy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-076b958a25a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nypd = pd.read_csv('new_york_edited copy.csv',\n\u001b[0m\u001b[1;32m      2\u001b[0m                    keep_date_col = ['closed_date','calendar_year'], index_col=['calendar_year'], na_filter=False)\n\u001b[1;32m      3\u001b[0m nypd.drop(['claim_number', 'summary_allegations', 'incident_date', 'filed_date','plaintiff_attorney',\n\u001b[1;32m      4\u001b[0m            \u001b[0;34m'plaintiff_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'incident_year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filed_year'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'other_expenses'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'collection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total_incurred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'court'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            'docket_number','matter_name','location','case_outcome',],\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'new_york_edited copy.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "nypd = pd.read_csv('new_york_edited copy.csv',\n",
    "                   keep_date_col = ['closed_date','calendar_year'], index_col=['calendar_year'], na_filter=False)\n",
    "nypd.drop(['claim_number', 'summary_allegations', 'incident_date', 'filed_date','plaintiff_attorney',\n",
    "           'plaintiff_name','incident_year', 'filed_year','other_expenses', 'collection','total_incurred','court',\n",
    "           'docket_number','matter_name','location','case_outcome',],\n",
    "            axis=1, inplace=True)\n",
    "dc = pd.read_csv('DC_edited copy.csv',\n",
    "                 keep_date_col=['closed_date','calendar_year'],index_col=['calendar_year'], na_filter=False)\n",
    "dc.drop(['matter_name','longer_description','filed_date','disposition_date','status', 'case_outcome',\n",
    "         'docket_number', 'summary_allegations','filed_year','incident_date', 'incident_year', 'location',\n",
    "         'other_expenses','collection', 'total_incurred','claim_number', 'court','plaintiff_name', \n",
    "         'plaintiff_attorney'],\n",
    "          axis=1,inplace=True,)\n",
    "detroit = pd.read_csv('detroit_edited copy.csv',\n",
    "                keep_date_col=['closed_date','calendar_year'], index_col=['calendar_year'], na_filter=False)\n",
    "detroit.drop(['incident_date','incident_year','filed_date','filed_year','other_expenses','collection', \n",
    "              'total_incurred','case_outcome','docket_number','claim_number','court','plaintiff_name',\n",
    "              'plaintiff_attorney', 'matter_name', 'location','summary_allegations'],\n",
    "             axis=1,inplace=True)\n",
    "atl = pd.read_csv('atlanta_edited copy.csv',\n",
    "                 index_col=['calendar_year'], na_filter=False)\n",
    "atl.drop(['incident_date', 'plaintiff_name', 'claim_or_lawsuit','denied_date', 'incident_year','matter_name',\n",
    "          'court', 'docket_number', 'filed_date', 'filed_year','location', 'other_expenses', 'collection', \n",
    "          'total_incurred','claim_number','summary_allegations','plaintiff_attorney', 'case_outcome', \n",
    "          'amount_demanded'],axis=1, inplace=True)\n",
    "ftlauderdale = pd.read_csv('fort_lauderdale_edited copy.csv',\n",
    "                          index_col=['calendar_year'], na_filter=False)\n",
    "ftlauderdale.drop(['incident_date','filed_date', 'filed_year','docket_number', 'claim_number', 'court', \n",
    "                   'plaintiff_name','matter_name', 'plaintiff_attorney','incident_year','collection',\n",
    "                   'case_outcome', 'location', 'summary_allegations','total_incurred','other_expenses'],axis=1,inplace=True)\n",
    "richmond = pd.read_csv('richmond_edited copy.csv',\n",
    "                      index_col=['calendar_year'], na_filter=False)\n",
    "richmond.drop(['court', 'matter_name', 'docket_number', 'incident_date','summary_allegations','filed_date', \n",
    "               'filed_year','case_outcome', 'collection', 'plaintiff', 'plaintiff_attorney','case_number',\n",
    "               'location','other_expenses','total_incurred','incident_year'],axis=1, inplace=True)\n",
    "st_louis = pd.read_csv('stlouis_edited copy.csv',\n",
    "                      index_col=['calendar_year'], na_filter=False)\n",
    "st_louis.drop(['incident_date','incident_year','filed_date','filed_year','other_expenses','claim_number','collection',\n",
    "               'total_incurred','case_outcome','docket_number','court','plaintiff_name','plaintiff_attorney',\n",
    "               'matter_name','location','summary_allegations','defendant_attorney','voucher_date','plaintiff_lawfirm'],\n",
    "              axis=1,inplace=True)\n",
    "roanoke_va = pd.read_csv('roanoke_edited copy.csv',\n",
    "                        index_col=['calendar_year'], na_filter=False)\n",
    "roanoke_va.drop(['incident_date', 'incident_year','filed_date', 'filed_year','other_expenses', 'collection', 'total_incurred', 'case_outcome',\n",
    "'docket_number', 'claim_number', 'court', 'plaintiff_name','plaintiff_attorney', 'matter_name', 'location', \n",
    "'summary_allegations','other_expenses', 'collection', 'total_incurred', 'case_outcome','docket_number', 'claim_number', 'court', 'plaintiff_name',\n",
    "'plaintiff_attorney', 'matter_name', 'location'],\n",
    "              axis=1, inplace=True)\n",
    "waterbury_ct = pd.read_csv('waterbury_edited copy.csv',\n",
    "                          index_col=['calendar_year'], na_filter=False)\n",
    "waterbury_ct.drop(['plaintiff_name', 'defendant', 'case_outcome','summary_allegations','docket_number','filed_date','filed_year',\n",
    "'matter_name','court','incident_date','location','incident_year','other_expenses','collection','total_incurred','claim_number'], \n",
    "                  axis=1,inplace=True)\n",
    "springfield = pd.read_csv('springfield_edited copy.csv',\n",
    "                         index_col=['calendar_year'], na_filter=False)\n",
    "springfield.drop(['incident_date', 'incident_year',\n",
    "'filed_date', 'filed_year','other_expenses', 'collection', 'total_incurred', 'case_outcome','docket_number', \n",
    "'claim_number', 'court', 'plaintiff_name','matter_name', 'plaintiff_attorney', 'location', 'summary_allegations'],\n",
    "                 axis=1, inplace=True)\n",
    "north_charleston = pd.read_csv('north_charleston_edited copy.csv',\n",
    "                               index_col=['calendar_year'], na_filter=False)\n",
    "north_charleston.drop(['incident_date','filed_date', 'filed_year','collection','incident_date','incident_year',\n",
    "'case_outcome','docket_number','claim_number','court','plaintiff_name','plaintiff_attorney',\n",
    "'matter_name','location','summary_allegations','defendant_name','defendant_attorney','total_incurred','other_expenses'],\n",
    "                      axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining csv's and assigning a variable using append funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_d = nypd.append([dc,detroit,atl,ftlauderdale,richmond,\n",
    "                                 st_louis,roanoke_va,waterbury_ct,springfield,north_charleston,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting new data frame to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_d.to_csv('combined_cities_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
